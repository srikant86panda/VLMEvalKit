{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def md5(s):\n",
    "    hash = hashlib.new('md5')\n",
    "    if os.path.exists(s):\n",
    "        with open(s, 'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(2**20), b''):\n",
    "                hash.update(chunk)\n",
    "    else:\n",
    "        hash.update(s.encode('utf-8'))\n",
    "    return str(hash.hexdigest())\n",
    "\n",
    "def encode_image(img, target_size=-1, fmt='JPEG'):\n",
    "    # if target_size == -1, will not do resizing\n",
    "    # else, will set the max_size ot (target_size, target_size)\n",
    "    if img.mode in ('RGBA', 'P'):\n",
    "        img = img.convert('RGB')\n",
    "    if target_size > 0:\n",
    "        img.thumbnail((target_size, target_size))\n",
    "    img_buffer = io.BytesIO()\n",
    "    img.save(img_buffer, format=fmt)\n",
    "    image_data = img_buffer.getvalue()\n",
    "    ret = base64.b64encode(image_data).decode('utf-8')\n",
    "    return ret\n",
    "\n",
    "\n",
    "def encode_image_to_base64(img, target_size=-1):\n",
    "    return encode_image(img, target_size=target_size)\n",
    "\n",
    "\n",
    "# def decode_base64(base64_string, target_size=-1):\n",
    "#     image_data = base64.b64decode(base64_string)\n",
    "#     image = Image.open(io.BytesIO(image_data))\n",
    "#     if image.mode in ('RGBA', 'P'):\n",
    "#         image = image.convert('RGB')\n",
    "#     if target_size > 0:\n",
    "#         image.thumbnail((target_size, target_size))\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def decode_base64_to_image(base64_string, target_size=-1):\n",
    "#     image = decode_base64(base64_string, target_size=target_size)\n",
    "#     return image\n",
    "\n",
    "def decode_base64(base64_string, target_size=-1):\n",
    "    # Add padding to the base64 string if necessary\n",
    "    missing_padding = len(base64_string) % 4\n",
    "    if missing_padding:\n",
    "        base64_string += '=' * (4 - missing_padding)\n",
    "    \n",
    "    try:\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to decode base64 string: {e}\")\n",
    "    \n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    if image.mode in ('RGBA', 'P'):\n",
    "        image = image.convert('RGB')\n",
    "    if target_size > 0:\n",
    "        image.thumbnail((target_size, target_size))\n",
    "    return image\n",
    "\n",
    "def decode_base64_to_image(base64_string, target_size=-1):\n",
    "    return decode_base64(base64_string, target_size=target_size)\n",
    "\n",
    "def split_image(img, target_section=None, grid_size=(3, 3), encode=False):\n",
    "    \"\"\"\n",
    "    Split an image into patches based on a given grid size.\n",
    "\n",
    "    Args:\n",
    "        img: PIL.Image object.\n",
    "        grid_size: Tuple specifying the number of rows and columns for the grid (rows, columns).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of cropped patches.\n",
    "    \"\"\"\n",
    "    width, height = img.size\n",
    "    num_rows, num_cols = grid_size\n",
    "\n",
    "    if num_rows < 1 or num_cols < 1:\n",
    "        raise ValueError(\"grid_size must contain positive integers for rows and columns.\")\n",
    "\n",
    "    # Calculate patch dimensions\n",
    "    patch_width = width / num_cols\n",
    "    patch_height = height / num_rows\n",
    "\n",
    "    grid_name = f'grid_{grid_size[0]}x{grid_size[1]}'\n",
    "    # Generate patches\n",
    "    patches = {}\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            left = int(col * patch_width)\n",
    "            upper = int(row * patch_height)\n",
    "            right = int((col + 1) * patch_width)\n",
    "            lower = int((row + 1) * patch_height)\n",
    "            section_name = f\"row{row+1}_col{col+1}\"\n",
    "            patches[f'{grid_name}_{section_name}'] = encode_image_to_base64(img.crop((left, upper, right, lower))) if encode else img.crop((left, upper, right, lower))\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the TSV file\n",
    "input_file = \"/home/hiteshlp/LMUData/mme_realworld_lite.tsv\"  # Replace with the path to your TSV file\n",
    "data = pd.read_csv(input_file, sep='\\t')  # Read the TSV file\n",
    "\n",
    "# # Step 2: Calculate 10% of the data size and ensure a minimum of 500 rows\n",
    "# num_rows = max(int(len(data) * 0.1), 500)\n",
    "\n",
    "# # Step 3: Randomly select the required number of rows\n",
    "# subset_data = data.sample(n=num_rows, random_state=42)  # random_state ensures reproducibility\n",
    "\n",
    "# Step 4: Save the selected rows to a new TSV file\n",
    "output_file = \"/home/hiteshlp/LMUData/MME-RealWorld-Lite_sample.tsv\"  # Replace with your desired output file name\n",
    "data.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample.tsv written successfully, md5: f8f4be3b4ced9ebc7a26f9a583ccfa87\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_2x1_row1_col1.tsv written successfully, md5: 1911bf0930eb8cd3350f6182d69e49cc\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_2x1_row2_col1.tsv written successfully, md5: 0c5c025037e768ccd7aa525d3dd084a1\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_1x2_row1_col1.tsv written successfully, md5: 2693cfc1d51547f1e7ba966a959e013c\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_1x2_row1_col2.tsv written successfully, md5: 744811edd8aa3972cfa32fcbe8301b94\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_2x2_row1_col1.tsv written successfully, md5: cdfb5592fc2351c5d95524d5772097d5\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_2x2_row1_col2.tsv written successfully, md5: d44b047a7640947d76dbe8344c0670f5\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_2x2_row2_col1.tsv written successfully, md5: f9e25557a2d4ba6eb44aaf86490ced44\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_2x2_row2_col2.tsv written successfully, md5: 323f3832755f55cfd29fd098a2e916dc\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row1_col1.tsv written successfully, md5: 5c4749a0a4bd6614460ad957f14d7c70\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row1_col2.tsv written successfully, md5: dce1542ed2e1f15c17f0340ebf09cfe2\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row1_col3.tsv written successfully, md5: 6244c05614ce87f0fb4a3b3fddc2532b\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row2_col1.tsv written successfully, md5: 8e794cb8fa1b26a2a7a5366bf7ee9dd6\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row2_col2.tsv written successfully, md5: 0bd3fd9e9fe3a2669441016f8c95d9cd\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row2_col3.tsv written successfully, md5: 444550ac9441a12f4483974462c87224\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row3_col1.tsv written successfully, md5: 4406eb0da3c2683196c60a19b81721fa\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row3_col2.tsv written successfully, md5: 35594b02e721e163a66852e96836eb75\n",
      "op_file_path: /home/hiteshlp/LMUData/MME-RealWorld-Lite_sample_grid_3x3_row3_col3.tsv written successfully, md5: f117b52654ead07375b899ec1a745641\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = '/home/hiteshlp/LMUData/MME-RealWorld-Lite_sample.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Dictionary to store processed images\n",
    "all_list_of_imgs = {}\n",
    "all_list_of_imgs['image'] = df.image.tolist()\n",
    "\n",
    "for index, img in enumerate(df['image']):\n",
    "    all_crops = {}\n",
    "    \n",
    "    if not isinstance(img, str):\n",
    "        print(f\"Skipping row {index} due to non-string image value.\")\n",
    "        continue\n",
    "\n",
    "    # Try to process only valid base64 images\n",
    "    try:\n",
    "        img_decoded = decode_base64_to_image(img)      \n",
    "        # Apply various grid splits\n",
    "        img_crops = split_image(img_decoded, grid_size=(2, 1), encode=True)\n",
    "        all_crops.update(img_crops)\n",
    "        img_crops = split_image(img_decoded, grid_size=(1, 2), encode=True)\n",
    "        all_crops.update(img_crops)\n",
    "        img_crops = split_image(img_decoded, grid_size=(2, 2), encode=True)\n",
    "        all_crops.update(img_crops)\n",
    "        img_crops = split_image(img_decoded, grid_size=(3, 3), encode=True)\n",
    "        all_crops.update(img_crops)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row {index} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Store processed image crops\n",
    "    for label, crop in all_crops.items():\n",
    "        if label not in all_list_of_imgs:\n",
    "            all_list_of_imgs[label] = df['image'].tolist()  # Preserve original structure\n",
    "        all_list_of_imgs[label][index] = crop  # Replace only valid processed images\n",
    "\n",
    "# Write original file MD5\n",
    "print(f'original file_path: {file_path} written successfully, md5: {md5(file_path)}')\n",
    "\n",
    "# Save processed image crops\n",
    "for label, img_list in all_list_of_imgs.items():\n",
    "    if label != 'image':\n",
    "        temp_df = df.copy()\n",
    "        temp_df['image'] = img_list\n",
    "        op_file_path = f'{os.path.dirname(file_path)}/{os.path.basename(file_path).split(\".\")[0]}_{label}.tsv'\n",
    "        temp_df.to_csv(op_file_path, sep='\\t', index=False)\n",
    "        print(f'op_file_path: {op_file_path} written successfully, md5: {md5(op_file_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x7f5f568dc8b0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      9\u001b[0m     all_crops \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 10\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_base64_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     img_crops \u001b[38;5;241m=\u001b[39m split_image(img, grid_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), encode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     all_crops\u001b[38;5;241m.\u001b[39mupdate(img_crops)\n",
      "Cell \u001b[0;32mIn[1], line 70\u001b[0m, in \u001b[0;36mdecode_base64_to_image\u001b[0;34m(base64_string, target_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_base64_to_image\u001b[39m(base64_string, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase64_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m, in \u001b[0;36mdecode_base64\u001b[0;34m(base64_string, target_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to decode base64 string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     64\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/PIL/Image.py:3498\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3496\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3497\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3498\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f5f568dc8b0>"
     ]
    }
   ],
   "source": [
    "## RealWorldQA pre-processing\n",
    "file_path = '/home/hiteshlp/LMUData/MMBench_TEST_EN_V11_sample.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "all_list_of_imgs = {}\n",
    "all_list_of_imgs['image'] = df.image.tolist()\n",
    "\n",
    "for img in df['image']:\n",
    "    all_crops = {}\n",
    "    img = decode_base64_to_image(img)\n",
    "    img_crops = split_image(img, grid_size=(2, 1), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(1, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(2, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(3, 3), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "\n",
    "    for label, crop in all_crops.items():\n",
    "        if label not in all_list_of_imgs:\n",
    "            all_list_of_imgs[label] = [crop]\n",
    "        else:\n",
    "            all_list_of_imgs[label].append(crop)\n",
    "\n",
    "print(f'original file_path: {file_path} written successfully, md5: {md5(file_path)}')\n",
    "for label, img_list in all_list_of_imgs.items():\n",
    "    if label != 'image':\n",
    "        temp_df = df.copy()\n",
    "        temp_df['image'] = img_list\n",
    "        op_file_path = f'{os.path.dirname(file_path)}/{os.path.basename(file_path).split(\".\")[0]}_{label}.tsv'\n",
    "        temp_df.to_csv(op_file_path, sep='\\t')\n",
    "        print(f'op_file_path: {op_file_path} written successfully, md5: {md5(op_file_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x7fa93b083c90>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      9\u001b[0m     all_crops \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 10\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_base64_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     img_crops \u001b[38;5;241m=\u001b[39m split_image(img, grid_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), encode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     all_crops\u001b[38;5;241m.\u001b[39mupdate(img_crops)\n",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m, in \u001b[0;36mdecode_base64_to_image\u001b[0;34m(base64_string, target_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_base64_to_image\u001b[39m(base64_string, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase64_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m, in \u001b[0;36mdecode_base64\u001b[0;34m(base64_string, target_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_base64\u001b[39m(base64_string, target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     38\u001b[0m     image_data \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(base64_string)\n\u001b[0;32m---> 39\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     41\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/PIL/Image.py:3498\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3496\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3497\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3498\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7fa93b083c90>"
     ]
    }
   ],
   "source": [
    "## RealWorldQA pre-processing\n",
    "file_path = '/home/hiteshlp/LMUData/MME_sample.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "all_list_of_imgs = {}\n",
    "all_list_of_imgs['image'] = df.image.tolist()\n",
    "\n",
    "for img in df['image']:\n",
    "    all_crops = {}\n",
    "    img = decode_base64_to_image(img)\n",
    "    img_crops = split_image(img, grid_size=(2, 1), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(1, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(2, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(3, 3), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "\n",
    "    for label, crop in all_crops.items():\n",
    "        if label not in all_list_of_imgs:\n",
    "            all_list_of_imgs[label] = [crop]\n",
    "        else:\n",
    "            all_list_of_imgs[label].append(crop)\n",
    "\n",
    "print(f'original file_path: {file_path} written successfully, md5: {md5(file_path)}')\n",
    "for label, img_list in all_list_of_imgs.items():\n",
    "    if label != 'image':\n",
    "        temp_df = df.copy()\n",
    "        temp_df['image'] = img_list\n",
    "        op_file_path = f'{os.path.dirname(file_path)}/{os.path.basename(file_path).split(\".\")[0]}_{label}.tsv'\n",
    "        temp_df.to_csv(op_file_path, sep='\\t')\n",
    "        print(f'op_file_path: {op_file_path} written successfully, md5: {md5(op_file_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original file_path: /home/srikapan/LMUData/RealWorldQA.tsv written successfully, md5: 4de008f55dc4fd008ca9e15321dc44b7\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_2x1_row1_col1.tsv written successfully, md5: 23dd6bb085d7fc34b4501450285c2b65\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_2x1_row2_col1.tsv written successfully, md5: 1bb1973c44a95f26281afcbe5c1b0344\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_1x2_row1_col1.tsv written successfully, md5: 05f27eaaabbfda0b64510b5a40fd7904\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_1x2_row1_col2.tsv written successfully, md5: e64007802642df4f3bc8bf82f3470e09\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_2x2_row1_col1.tsv written successfully, md5: b9d02c2e82afbae3d8574fbebed3e1e6\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_2x2_row1_col2.tsv written successfully, md5: 7cdc6b709903e7be066dbc7862bb9a00\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_2x2_row2_col1.tsv written successfully, md5: 28d19d380f1e13e5266008374506c3ba\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_2x2_row2_col2.tsv written successfully, md5: 1fe65200b3cb57d521829472f6375164\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row1_col1.tsv written successfully, md5: 0ef5a1f5a2caefeb623177fa5cc3dd51\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row1_col2.tsv written successfully, md5: 469bde7d612953e032cf46394de307dd\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row1_col3.tsv written successfully, md5: 73dd3dbbd3ebf85369360902acbfafbf\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row2_col1.tsv written successfully, md5: 8116d7ab702a9bc1307af26d6b6aa5e2\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row2_col2.tsv written successfully, md5: 06a9ddb5d5b6769849cb7f913e724ad8\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row2_col3.tsv written successfully, md5: a851436bcb159683591fff6c758bdb78\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row3_col1.tsv written successfully, md5: 0c4e03b4c7a4b9375c0811b897bfa769\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row3_col2.tsv written successfully, md5: 4cf68f9ed12af00e55c917f7140f0b4b\n",
      "op_file_path: /home/srikapan/LMUData/RealWorldQA_grid_3x3_row3_col3.tsv written successfully, md5: 77483b061dd0dca5d08e8cddef7f15a3\n"
     ]
    }
   ],
   "source": [
    "## RealWorldQA pre-processing\n",
    "file_path = '/home/hiteshlp/LMUData/ChartQA_TEST.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "all_list_of_imgs = {}\n",
    "all_list_of_imgs['image'] = df.image.tolist()\n",
    "\n",
    "for img in df['image']:\n",
    "    all_crops = {}\n",
    "    img = decode_base64_to_image(img)\n",
    "    img_crops = split_image(img, grid_size=(2, 1), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(1, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(2, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(3, 3), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "\n",
    "    for label, crop in all_crops.items():\n",
    "        if label not in all_list_of_imgs:\n",
    "            all_list_of_imgs[label] = [crop]\n",
    "        else:\n",
    "            all_list_of_imgs[label].append(crop)\n",
    "\n",
    "print(f'original file_path: {file_path} written successfully, md5: {md5(file_path)}')\n",
    "for label, img_list in all_list_of_imgs.items():\n",
    "    if label != 'image':\n",
    "        temp_df = df.copy()\n",
    "        temp_df['image'] = img_list\n",
    "        op_file_path = f'{os.path.dirname(file_path)}/{os.path.basename(file_path).split(\".\")[0]}_{label}.tsv'\n",
    "        temp_df.to_csv(op_file_path, sep='\\t')\n",
    "        print(f'op_file_path: {op_file_path} written successfully, md5: {md5(op_file_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original file_path: /home/srikapan/LMUData/COCO_VAL_sample.tsv written successfully, md5: 5b6ed6e5f35024d003804372a13533c4\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_2x1_row1_col1.tsv written successfully, md5: 9999f71c872ada7193ac6f96e9c4030e\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_2x1_row2_col1.tsv written successfully, md5: 18ec1a575214bab28a2e50003e957299\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_1x2_row1_col1.tsv written successfully, md5: 6b02299cf429ca0ad398d01603688448\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_1x2_row1_col2.tsv written successfully, md5: 9ebee03bedc40d91c2fd08ff3dee1102\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_2x2_row1_col1.tsv written successfully, md5: f5e674127cc699ebfb77f66ba5581868\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_2x2_row1_col2.tsv written successfully, md5: 4c9f1408805b62e02695efe5cd546a1b\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_2x2_row2_col1.tsv written successfully, md5: b6a16dc21248550c2c287ffc5a6adeb3\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_2x2_row2_col2.tsv written successfully, md5: 149df47164d35499bfbf36481b2e8f5c\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row1_col1.tsv written successfully, md5: 7b5807ef64318afbe27858e48507eaae\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row1_col2.tsv written successfully, md5: e1640bc9276cf806e80248169b90b3d4\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row1_col3.tsv written successfully, md5: d12c40a377dcc8593ba1d745cd3867f7\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row2_col1.tsv written successfully, md5: 0359f4323e287b33c06fde01d2d8ca39\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row2_col2.tsv written successfully, md5: ffe43118269c9af4d703c0297a492053\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row2_col3.tsv written successfully, md5: 56ef9a830da851d0d225e6363d4ebe47\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row3_col1.tsv written successfully, md5: 3d81fb12514a28c410ba84f8b473087a\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row3_col2.tsv written successfully, md5: 830196882c5b8774a32a4f8ead8c6370\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_sample_grid_3x3_row3_col3.tsv written successfully, md5: f5f4996a9e79d8c90708f937f16d7936\n"
     ]
    }
   ],
   "source": [
    "## COCO sample pre-processing\n",
    "file_path = '/home/srikapan/LMUData/COCO_VAL_sample.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "all_list_of_imgs = {}\n",
    "all_list_of_imgs['image'] = df.image.tolist()\n",
    "\n",
    "for img in df['image']:\n",
    "    all_crops = {}\n",
    "    img = decode_base64_to_image(img)\n",
    "    img_crops = split_image(img, grid_size=(2, 1), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(1, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(2, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(3, 3), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "\n",
    "    for label, crop in all_crops.items():\n",
    "        if label not in all_list_of_imgs:\n",
    "            all_list_of_imgs[label] = [crop]\n",
    "        else:\n",
    "            all_list_of_imgs[label].append(crop)\n",
    "\n",
    "print(f'original file_path: {file_path} written successfully, md5: {md5(file_path)}')\n",
    "for label, img_list in all_list_of_imgs.items():\n",
    "    if label != 'image':\n",
    "        temp_df = df.copy()\n",
    "        temp_df['image'] = img_list\n",
    "        op_file_path = f'{os.path.dirname(file_path)}/{os.path.basename(file_path).split(\".\")[0]}_{label}.tsv'\n",
    "        temp_df.to_csv(op_file_path, sep='\\t')\n",
    "        print(f'op_file_path: {op_file_path} written successfully, md5: {md5(op_file_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original file_path: /home/srikapan/LMUData/COCO_VAL.tsv written successfully, md5: 72a5079dead060269ac222c5aa5128af\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_2x1_row1_col1.tsv written successfully, md5: a661f336357cc033c0ac362ce43c8934\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_2x1_row2_col1.tsv written successfully, md5: a81faa8e1616fc8893a1c9208358a8fb\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_1x2_row1_col1.tsv written successfully, md5: 220648e71ea09065a5e6c984c98d257d\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_1x2_row1_col2.tsv written successfully, md5: c0ccc20c7af4b1382a6c128ad449dd57\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_2x2_row1_col1.tsv written successfully, md5: a37fc00dab224f9ae041172b25ac8735\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_2x2_row1_col2.tsv written successfully, md5: f43fb8f80df717a53d1f441047cfd4c8\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_2x2_row2_col1.tsv written successfully, md5: 407cc5d794fb986fac4bebfd2eef09ca\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_2x2_row2_col2.tsv written successfully, md5: 0924bda06630c614fd74e22d4dd43690\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row1_col1.tsv written successfully, md5: 54aab03cd5a0efe08032f89a88131e67\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row1_col2.tsv written successfully, md5: 80d808b6c9246ecd013503c3ed553a9a\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row1_col3.tsv written successfully, md5: 039933f1adb271f7af61481933ba9e79\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row2_col1.tsv written successfully, md5: 27aadc2b62fd451690b61c6217d36a41\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row2_col2.tsv written successfully, md5: f8e7abca5ed106f5303e1a8c6a0c720e\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row2_col3.tsv written successfully, md5: 92283d89cd17aab740d0578adca10fad\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row3_col1.tsv written successfully, md5: d50f7854d5d0b27ded7c9ab46c838791\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row3_col2.tsv written successfully, md5: d43351ea6958510794c13db54f926b7c\n",
      "op_file_path: /home/srikapan/LMUData/COCO_VAL_grid_3x3_row3_col3.tsv written successfully, md5: cd8f8c222ca98a8375454f23d89cfb08\n"
     ]
    }
   ],
   "source": [
    "## COCO pre-processing\n",
    "file_path = '/home/srikapan/LMUData/COCO_VAL.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "all_list_of_imgs = {}\n",
    "all_list_of_imgs['image'] = df.image.tolist()\n",
    "\n",
    "for img in df['image']:\n",
    "    all_crops = {}\n",
    "    img = decode_base64_to_image(img)\n",
    "    img_crops = split_image(img, grid_size=(2, 1), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(1, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(2, 2), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "    img_crops = split_image(img, grid_size=(3, 3), encode=True)\n",
    "    all_crops.update(img_crops)\n",
    "\n",
    "    for label, crop in all_crops.items():\n",
    "        if label not in all_list_of_imgs:\n",
    "            all_list_of_imgs[label] = [crop]\n",
    "        else:\n",
    "            all_list_of_imgs[label].append(crop)\n",
    "\n",
    "print(f'original file_path: {file_path} written successfully, md5: {md5(file_path)}')\n",
    "for label, img_list in all_list_of_imgs.items():\n",
    "    if label != 'image':\n",
    "        temp_df = df.copy()\n",
    "        temp_df['image'] = img_list\n",
    "        op_file_path = f'{os.path.dirname(file_path)}/{os.path.basename(file_path).split(\".\")[0]}_{label}.tsv'\n",
    "        temp_df.to_csv(op_file_path, sep='\\t')\n",
    "        print(f'op_file_path: {op_file_path} written successfully, md5: {md5(op_file_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_VAL_grid_2x1_row1_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_2x1_row1_col1.tsv\n",
      "COCO_VAL_grid_2x1_row2_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_2x1_row2_col1.tsv\n",
      "COCO_VAL_grid_1x2_row1_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_1x2_row1_col1.tsv\n",
      "COCO_VAL_grid_1x2_row1_col2 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_1x2_row1_col2.tsv\n",
      "COCO_VAL_grid_2x2_row1_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_2x2_row1_col1.tsv\n",
      "COCO_VAL_grid_2x2_row1_col2 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_2x2_row1_col2.tsv\n",
      "COCO_VAL_grid_2x2_row2_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_2x2_row2_col1.tsv\n",
      "COCO_VAL_grid_2x2_row2_col2 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_2x2_row2_col2.tsv\n",
      "COCO_VAL_grid_3x3_row1_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row1_col1.tsv\n",
      "COCO_VAL_grid_3x3_row1_col2 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row1_col2.tsv\n",
      "COCO_VAL_grid_3x3_row1_col3 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row1_col3.tsv\n",
      "COCO_VAL_grid_3x3_row2_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row2_col1.tsv\n",
      "COCO_VAL_grid_3x3_row2_col2 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row2_col2.tsv\n",
      "COCO_VAL_grid_3x3_row2_col3 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row2_col3.tsv\n",
      "COCO_VAL_grid_3x3_row3_col1 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row3_col1.tsv\n",
      "COCO_VAL_grid_3x3_row3_col2 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row3_col2.tsv\n",
      "COCO_VAL_grid_3x3_row3_col3 : https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/COCO_VAL_grid_3x3_row3_col3.tsv\n"
     ]
    }
   ],
   "source": [
    "dic = {'COCO_VAL_grid_2x1_row1_col1' : 'a661f336357cc033c0ac362ce43c8934',\n",
    "'COCO_VAL_grid_2x1_row2_col1' : 'a81faa8e1616fc8893a1c9208358a8fb',\n",
    "'COCO_VAL_grid_1x2_row1_col1' : '220648e71ea09065a5e6c984c98d257d',\n",
    "'COCO_VAL_grid_1x2_row1_col2' : 'c0ccc20c7af4b1382a6c128ad449dd57',\n",
    "'COCO_VAL_grid_2x2_row1_col1' : 'a37fc00dab224f9ae041172b25ac8735',\n",
    "'COCO_VAL_grid_2x2_row1_col2' : 'f43fb8f80df717a53d1f441047cfd4c8',\n",
    "'COCO_VAL_grid_2x2_row2_col1' : '407cc5d794fb986fac4bebfd2eef09ca',\n",
    "'COCO_VAL_grid_2x2_row2_col2' : '0924bda06630c614fd74e22d4dd43690',\n",
    "'COCO_VAL_grid_3x3_row1_col1' : '54aab03cd5a0efe08032f89a88131e67',\n",
    "'COCO_VAL_grid_3x3_row1_col2' : '80d808b6c9246ecd013503c3ed553a9a',\n",
    "'COCO_VAL_grid_3x3_row1_col3' : '039933f1adb271f7af61481933ba9e79',\n",
    "'COCO_VAL_grid_3x3_row2_col1' : '27aadc2b62fd451690b61c6217d36a41',\n",
    "'COCO_VAL_grid_3x3_row2_col2' : 'f8e7abca5ed106f5303e1a8c6a0c720e',\n",
    "'COCO_VAL_grid_3x3_row2_col3' : '92283d89cd17aab740d0578adca10fad',\n",
    "'COCO_VAL_grid_3x3_row3_col1' : 'd50f7854d5d0b27ded7c9ab46c838791',\n",
    "'COCO_VAL_grid_3x3_row3_col2' : 'd43351ea6958510794c13db54f926b7c',\n",
    "'COCO_VAL_grid_3x3_row3_col3' : 'cd8f8c222ca98a8375454f23d89cfb08',}\n",
    "\n",
    "for i in dic.keys():\n",
    "    print(i, ':', f'https://huggingface.co/datasets/Srikant86/VLMEval/resolve/main/COCO_VAL/{i}.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
